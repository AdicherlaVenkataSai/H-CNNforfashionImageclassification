{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG16.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "tVGoQZUBcq3b",
        "71eJ9GL9eGxR",
        "J6jvkFNwVpCI"
      ],
      "mount_file_id": "1DNKqGkTviamET2VVeSLvxWX_R41tDUeB",
      "authorship_tag": "ABX9TyP3ujT+FlE7pWlcacojtqaR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdicherlaVenkataSai/Hierarichal-Convolutional-Neural-Network-for-fashion-Image-Classification/blob/master/VGG16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eduqjrXbo33",
        "colab_type": "text"
      },
      "source": [
        "# Implementing VGGNET-16 on FashioMNIST \n",
        "\n",
        ">FashionMNIST is a dataset consists of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28*28 grayscale images, associated with a lable from 10 classes.\n",
        "\n",
        "In this work, the pre-trained model VGG19."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPWgV1z4d19R",
        "colab_type": "text"
      },
      "source": [
        "Requirements:\n",
        ">1. google colab(GPU)\n",
        "2. dataset(fashion MNIST)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVGoQZUBcq3b",
        "colab_type": "text"
      },
      "source": [
        "### 1. load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LufyJJYNbanX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "data_train = pd.read_csv('drive/My Drive/dataset/fashion-mnist_train.csv')\n",
        "data_test = pd.read_csv('drive/My Drive/dataset/fashion-mnist_test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDIm7RKldadf",
        "colab_type": "text"
      },
      "source": [
        ">note:\n",
        "1. I have loaded .csv files of fashionMNIST dataset from the google drive.\n",
        "2. While executing kindly adjust the path accordingly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6G3yZIChDOa",
        "colab_type": "code",
        "outputId": "113296da-8c94-45b9-c29e-fd00263a2cd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "data_train.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>pixel39</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>105</td>\n",
              "      <td>92</td>\n",
              "      <td>101</td>\n",
              "      <td>107</td>\n",
              "      <td>100</td>\n",
              "      <td>132</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>...</td>\n",
              "      <td>211</td>\n",
              "      <td>220</td>\n",
              "      <td>214</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>255</td>\n",
              "      <td>222</td>\n",
              "      <td>128</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>134</td>\n",
              "      <td>162</td>\n",
              "      <td>191</td>\n",
              "      <td>214</td>\n",
              "      <td>163</td>\n",
              "      <td>146</td>\n",
              "      <td>165</td>\n",
              "      <td>79</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>43</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>114</td>\n",
              "      <td>183</td>\n",
              "      <td>112</td>\n",
              "      <td>55</td>\n",
              "      <td>23</td>\n",
              "      <td>72</td>\n",
              "      <td>102</td>\n",
              "      <td>165</td>\n",
              "      <td>160</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>188</td>\n",
              "      <td>163</td>\n",
              "      <td>93</td>\n",
              "      <td>...</td>\n",
              "      <td>171</td>\n",
              "      <td>249</td>\n",
              "      <td>207</td>\n",
              "      <td>197</td>\n",
              "      <td>202</td>\n",
              "      <td>45</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>21</td>\n",
              "      <td>25</td>\n",
              "      <td>69</td>\n",
              "      <td>52</td>\n",
              "      <td>45</td>\n",
              "      <td>74</td>\n",
              "      <td>39</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>68</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>187</td>\n",
              "      <td>189</td>\n",
              "      <td>...</td>\n",
              "      <td>230</td>\n",
              "      <td>237</td>\n",
              "      <td>229</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>68</td>\n",
              "      <td>116</td>\n",
              "      <td>112</td>\n",
              "      <td>136</td>\n",
              "      <td>147</td>\n",
              "      <td>144</td>\n",
              "      <td>121</td>\n",
              "      <td>102</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  pixel1  pixel2  pixel3  ...  pixel781  pixel782  pixel783  pixel784\n",
              "0      2       0       0       0  ...         0         0         0         0\n",
              "1      9       0       0       0  ...         0         0         0         0\n",
              "2      6       0       0       0  ...         0         0         0         0\n",
              "3      0       0       0       0  ...         0         0         0         0\n",
              "4      3       0       0       0  ...         0         0         0         0\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moQOp74ahGdD",
        "colab_type": "code",
        "outputId": "d8c033bc-478b-4ad7-fdd3-d71be7dcb9e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "data_test.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>pixel39</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>29</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>242</td>\n",
              "      <td>245</td>\n",
              "      <td>224</td>\n",
              "      <td>245</td>\n",
              "      <td>234</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>37</td>\n",
              "      <td>69</td>\n",
              "      <td>94</td>\n",
              "      <td>123</td>\n",
              "      <td>127</td>\n",
              "      <td>138</td>\n",
              "      <td>138</td>\n",
              "      <td>142</td>\n",
              "      <td>145</td>\n",
              "      <td>135</td>\n",
              "      <td>125</td>\n",
              "      <td>103</td>\n",
              "      <td>87</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>209</td>\n",
              "      <td>190</td>\n",
              "      <td>181</td>\n",
              "      <td>150</td>\n",
              "      <td>170</td>\n",
              "      <td>193</td>\n",
              "      <td>180</td>\n",
              "      <td>219</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>...</td>\n",
              "      <td>248</td>\n",
              "      <td>238</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>174</td>\n",
              "      <td>233</td>\n",
              "      <td>155</td>\n",
              "      <td>0</td>\n",
              "      <td>65</td>\n",
              "      <td>235</td>\n",
              "      <td>216</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>53</td>\n",
              "      <td>99</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>94</td>\n",
              "      <td>68</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>106</td>\n",
              "      <td>94</td>\n",
              "      <td>89</td>\n",
              "      <td>94</td>\n",
              "      <td>68</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>87</td>\n",
              "      <td>12</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>46</td>\n",
              "      <td>50</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "      <td>53</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>161</td>\n",
              "      <td>212</td>\n",
              "      <td>138</td>\n",
              "      <td>150</td>\n",
              "      <td>169</td>\n",
              "      <td>164</td>\n",
              "      <td>176</td>\n",
              "      <td>202</td>\n",
              "      <td>255</td>\n",
              "      <td>183</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>129</td>\n",
              "      <td>221</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>215</td>\n",
              "      <td>...</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>254</td>\n",
              "      <td>252</td>\n",
              "      <td>255</td>\n",
              "      <td>101</td>\n",
              "      <td>196</td>\n",
              "      <td>254</td>\n",
              "      <td>252</td>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>168</td>\n",
              "      <td>232</td>\n",
              "      <td>225</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>172</td>\n",
              "      <td>147</td>\n",
              "      <td>148</td>\n",
              "      <td>153</td>\n",
              "      <td>155</td>\n",
              "      <td>146</td>\n",
              "      <td>137</td>\n",
              "      <td>141</td>\n",
              "      <td>143</td>\n",
              "      <td>137</td>\n",
              "      <td>137</td>\n",
              "      <td>126</td>\n",
              "      <td>140</td>\n",
              "      <td>0</td>\n",
              "      <td>133</td>\n",
              "      <td>224</td>\n",
              "      <td>222</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>204</td>\n",
              "      <td>235</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>69</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  pixel1  pixel2  pixel3  ...  pixel781  pixel782  pixel783  pixel784\n",
              "0      0       0       0       0  ...         0         0         0         0\n",
              "1      1       0       0       0  ...         0         0         0         0\n",
              "2      2       0       0       0  ...        31         0         0         0\n",
              "3      2       0       0       0  ...       222        56         0         0\n",
              "4      3       0       0       0  ...         0         0         0         0\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dy1FtHEmhKKD",
        "colab_type": "code",
        "outputId": "80e1bd8f-4b87-4354-848c-cfee66ea5c0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_train.shape, data_test.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 785), (10000, 785))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71eJ9GL9eGxR",
        "colab_type": "text"
      },
      "source": [
        "### 2. Pre-processing data\n",
        "> ##### a  \n",
        "Images and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8BzIWONdWQG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "# X = training images, y =training labels\n",
        " \n",
        "X = np.array(data_train.iloc[:,1:])\n",
        "y = to_categorical(np.array(data_train.iloc[:,0]))\n",
        "\n",
        "# X_test = test images, y_test = test labels\n",
        "X_test = np.array(data_test.iloc[:, 1:])\n",
        "y_test = to_categorical(np.array(data_test.iloc[:, 0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOClxicte5ol",
        "colab_type": "text"
      },
      "source": [
        ">note:\n",
        "1. iloc returns a Pandas Series when one row is selected, and a Pandas DataFrame when multiple rows are selected, or if any column in full is selected.\n",
        "2. One hot encoding is applied on y, y_test using to_categorical() which is avail with in the keras.utils( tensorflow backend)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttcEFgdNe0ZL",
        "colab_type": "code",
        "outputId": "2ea1e9f5-2620-4ee7-e2fd-3b31a5ff9943",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# look at the shape of the dataframes\n",
        "X.shape, X_test.shape, y.shape, y_test.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 784), (10000, 784), (60000, 10), (10000, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1eKGbq9hU-D",
        "colab_type": "text"
      },
      "source": [
        "> ##### b\n",
        " The images of the fashionMNIST are black and white, while the required input for VGG19 must be colored image. Thus covert the images into colored one with 3 channes R, G, B."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77_kiAeyg16Z",
        "colab_type": "code",
        "outputId": "65518550-0841-4fec-8029-526fac87c4ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "X = np.dstack([X] * 3)\n",
        "X_test = np.dstack([X_test] * 3)\n",
        "\n",
        "X.shape, X_test.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 784, 3), (10000, 784, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwfAS8cPpADf",
        "colab_type": "text"
      },
      "source": [
        "> ##### c\n",
        "Reshape the images into tensor format as required by TensoFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mwne-Poko-Rn",
        "colab_type": "code",
        "outputId": "df9595a5-1c40-4636-ade5-8a389be30aa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "X = X.reshape(-1, 28, 28, 3)\n",
        "X_test = X_test.reshape(-1, 28, 28, 3)\n",
        "\n",
        "X.shape, X_test.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28, 3), (10000, 28, 28, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVD-PixvprnO",
        "colab_type": "text"
      },
      "source": [
        "> ##### d\n",
        "VGG19 requires min input image's width and height of 48."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJ1T-F6eiZbG",
        "colab_type": "code",
        "outputId": "1305978e-9b8b-49ef-aee1-d1562488ed5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "\n",
        "from keras.preprocessing.image import img_to_array, array_to_img\n",
        "\n",
        "X = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48,48))) for im in X])\n",
        "X_test = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48,48))) for im in X_test])\n",
        "\n",
        "X.shape, X_test.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 48, 48, 3), (10000, 48, 48, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-zsJhe2txYO",
        "colab_type": "text"
      },
      "source": [
        "> ##### e\n",
        "pre-process the images by reshaping and scaling them so that all values are in the [0, 1] interval."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTZnffRrtC0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = X.astype('float32')\n",
        "X /= 255\n",
        "\n",
        "X_test = X_test.astype('float32')\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6jvkFNwVpCI",
        "colab_type": "text"
      },
      "source": [
        "### 3. Split the data\n",
        "> The original training data (60k images) is split into 80% of training(48k images) and 20% of validation (12k images), to finally evaluate the accuracy of the model on the data it has never seen. This helps to see whether overfitting the training data or not?. Whether i should lower the learning rate and train more epochs if validation accuracy is higher than traning accuracy or stop over-training if training accuracy shift higher than the validation. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkTN8VmXVfi7",
        "colab_type": "code",
        "outputId": "82b7856d-a438-45e6-abcb-3839872df0b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size =  0.2, random_state = 50)\n",
        "\n",
        "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((48000, 48, 48, 3), (12000, 48, 48, 3), (48000, 10), (12000, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6aaJnLGZEfL",
        "colab_type": "text"
      },
      "source": [
        "### 4. VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EkFj5fuYmtL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications import VGG16\n",
        "\n",
        "vgg16 = VGG16(weights = 'imagenet', include_top = False, input_shape = (48,48,3), classes = 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBLY8oVlZ9_3",
        "colab_type": "text"
      },
      "source": [
        "> note: Passed arguments are\n",
        "1. weights specifies the weeight checkpoint fromwhich to intitialize the model.\n",
        "2. include_top  refers to including(or not) the densely connected classifier on top of the network. By default, this densely connected classifer corresponds to the 1000 classes from ImageNet. As in this were are different densely connected classifier with only 10 classes, so no need to include it\n",
        "3. input_shape(optional), only to be included if include_top is false\n",
        "4. classes(optional), no of classes to classify images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aT2i5_eYtVh",
        "colab_type": "code",
        "outputId": "c6f73159-ba55-4c30-b2ba-210684f05027",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "vgg16.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 48, 48, 3)         0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 48, 48, 64)        1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 48, 48, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 24, 24, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 24, 24, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 12, 12, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 12, 12, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 12, 12, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 6, 6, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqxZqf53bfOP",
        "colab_type": "text"
      },
      "source": [
        "### 5. Feature extraction\n",
        "> feature extraction consists of represetations learned by a previous network to extract interesting features from new samples. These features are then run through a new classifier, which is trained from scratch.\n",
        "\n",
        "> CNNs used for image classification comprise two parts; \n",
        "1. start with a series of pooling and convolution layers(CONVOLUTIONAL BASE)\n",
        "2. end with a densely connected classifer.\n",
        "\n",
        "> In case of covnets, 'feature extraction' will simply consist of taking the convolutional base of previously trained network, running the new data through it and training a new classifier on top of the output.\n",
        "\n",
        "> why only reuse the convolutional base? could we reuse the densely connected classifier as well? In general, it should be avoided. The reason is simple that the representations learned by the convolutional base are likely to be more generic(common) and therfore more reusable, the feature maps of a covnet are presence maps of generic(common) concpets over a picture which is likely useful regardless of the problem.\n",
        "\n",
        ">Representaations learned by the classifier will necessarily be very specific to the set of classes that the model was trained on, they will only contain information abou the presence probability of a class in the entire picture. Aditionally representations found in densely connected layers no longer contan any information about where objects are located in the input image, these layers get rid of the notion of space, whereas the object locaton is still described by convolutional feature maps. For objects where object location matters, densely connected features woulld be useless.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WKSUswZbevA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "#pre processing the input\n",
        "X_train = preprocess_input(X_train)\n",
        "X_val = preprocess_input(X_val)\n",
        "X_test = preprocess_input(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aICHO5qhc84",
        "colab_type": "text"
      },
      "source": [
        "\n",
        ">Now inorder to extract features from the FashionMNIST data:\n",
        "1. Run the convolutional base over the dataset\n",
        "2. Record its output to a numpy array on disk\n",
        "3. Use this data as input to a standalone densely connected classifer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYgH8TcAf46V",
        "colab_type": "code",
        "outputId": "1faf6b8f-6f39-421f-86d3-eb80da1a89f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# feature extraction\n",
        "\n",
        "train_features = vgg16.predict(np.array(X_train), batch_size = 256, verbose =1)\n",
        "val_features = vgg16.predict(np.array(X_val), batch_size = 256, verbose =1)\n",
        "test_features = vgg16.predict(np.array(X_test), batch_size = 256, verbose =1)\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "48000/48000 [==============================] - 32s 661us/step\n",
            "12000/12000 [==============================] - 7s 613us/step\n",
            "10000/10000 [==============================] - 5s 527us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pedokIqiujM",
        "colab_type": "code",
        "outputId": "ccb8d2d4-33b0-4a87-c3e4-9d785f89bdc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# shape of features\n",
        "\n",
        "train_features.shape, val_features.shape, test_features.shape "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((48000, 1, 1, 512), (12000, 1, 1, 512), (10000, 1, 1, 512))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_-Dtqdwj1jP",
        "colab_type": "text"
      },
      "source": [
        "> note: The extracted featires are currently of shape (samples, 1, 1, 512). \n",
        "\n",
        ">Feed them to a densely connected classifer, before that flatten them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuH5okRij0q7",
        "colab_type": "code",
        "outputId": "8c08d079-b242-48de-f3a0-8bd7f677d78d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# flatten extracted features\n",
        "\n",
        "train_features = np.reshape(train_features, (48000, 1*1*512))\n",
        "val_features = np.reshape(val_features, (12000, 1*1*512))\n",
        "test_features = np.reshape(test_features, (10000, 1*1*512))\n",
        "\n",
        "# shape of features\n",
        "\n",
        "train_features.shape, val_features.shape, test_features.shape "
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((48000, 512), (12000, 512), (10000, 512))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcH1Fc68k7x5",
        "colab_type": "text"
      },
      "source": [
        "> Define desenly connected classifer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpKE9PxnjYAt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Dense, Dropout\n",
        "from keras.models import Model\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "\n",
        "# adding Dense and Dropout layers on top of VGG16\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(4096, activation = 'relu', input_dim = 1*1*512))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(10, activation = 'softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UT4Qx7g-mEPE",
        "colab_type": "text"
      },
      "source": [
        "> note: To prevent overfitting, dropout reeguarization is processed between fully-connected layers. In prediction block 4096 channels are divided into 10 classes using softmax activation function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJZAHHsmmDtE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "\n",
        "#compile the model\n",
        "\n",
        "model.compile(loss = keras.losses.categorical_crossentropy,\n",
        "              optimizer = keras.optimizers.Adam(),\n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJ1-XGabm1S4",
        "colab_type": "text"
      },
      "source": [
        "> note:  When compiling the model, I choose categorical_crossentropy as the loss function (which is relevent for multiclass, single-label classification problem) and Adam optimizer.\n",
        "1. The cross-entropy loss calculates the error rate between the predicted value and the original value. Categorical is used because there are 10 classes to predict from. If there were 2 classes we can use binary_crossentropy.\n",
        "2. The Adam optimizer is an improvement over SGD(Stochastic Gradient Descent). The optimizer is responsible for updating the weights of the neurons via backpropagation. It calculates the derivative of the loss function with respect to each weight and subtracts it from the weight.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anv9Rke9nVlr",
        "colab_type": "text"
      },
      "source": [
        "### 6. Train the model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKvX1R8Nl-Lr",
        "colab_type": "code",
        "outputId": "30a25841-8bc1-44a2-846b-4b7fa6fa2691",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(train_features, y_train, batch_size = 256, epochs = 100, verbose = 1, validation_data=(val_features, y_val))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/100\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 2.0704 - accuracy: 0.3418 - val_loss: 1.3495 - val_accuracy: 0.4966\n",
            "Epoch 2/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 1.2993 - accuracy: 0.5180 - val_loss: 1.1662 - val_accuracy: 0.5872\n",
            "Epoch 3/100\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 1.1620 - accuracy: 0.5768 - val_loss: 1.0759 - val_accuracy: 0.6133\n",
            "Epoch 4/100\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 1.1025 - accuracy: 0.5942 - val_loss: 1.0301 - val_accuracy: 0.6325\n",
            "Epoch 5/100\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 1.0483 - accuracy: 0.6160 - val_loss: 0.9792 - val_accuracy: 0.6562\n",
            "Epoch 6/100\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 1.0203 - accuracy: 0.6270 - val_loss: 0.9656 - val_accuracy: 0.6616\n",
            "Epoch 7/100\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 0.9938 - accuracy: 0.6379 - val_loss: 0.9407 - val_accuracy: 0.6634\n",
            "Epoch 8/100\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 0.9756 - accuracy: 0.6455 - val_loss: 0.9261 - val_accuracy: 0.6597\n",
            "Epoch 9/100\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 0.9699 - accuracy: 0.6473 - val_loss: 0.9179 - val_accuracy: 0.6640\n",
            "Epoch 10/100\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 0.9597 - accuracy: 0.6482 - val_loss: 0.8954 - val_accuracy: 0.6802\n",
            "Epoch 11/100\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 0.9454 - accuracy: 0.6551 - val_loss: 0.8998 - val_accuracy: 0.6727\n",
            "Epoch 12/100\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 0.9365 - accuracy: 0.6578 - val_loss: 0.8887 - val_accuracy: 0.6741\n",
            "Epoch 13/100\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 0.9268 - accuracy: 0.6604 - val_loss: 0.8920 - val_accuracy: 0.6705\n",
            "Epoch 14/100\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 0.9229 - accuracy: 0.6635 - val_loss: 0.8721 - val_accuracy: 0.6828\n",
            "Epoch 15/100\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 0.9139 - accuracy: 0.6646 - val_loss: 0.8925 - val_accuracy: 0.6808\n",
            "Epoch 16/100\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 0.9220 - accuracy: 0.6636 - val_loss: 0.8509 - val_accuracy: 0.6923\n",
            "Epoch 17/100\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 0.9117 - accuracy: 0.6691 - val_loss: 0.8796 - val_accuracy: 0.6707\n",
            "Epoch 18/100\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 0.9155 - accuracy: 0.6650 - val_loss: 0.8615 - val_accuracy: 0.6928\n",
            "Epoch 19/100\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 0.9014 - accuracy: 0.6726 - val_loss: 0.8542 - val_accuracy: 0.6846\n",
            "Epoch 20/100\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 0.9021 - accuracy: 0.6715 - val_loss: 0.8324 - val_accuracy: 0.6988\n",
            "Epoch 21/100\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 0.8910 - accuracy: 0.6752 - val_loss: 0.8327 - val_accuracy: 0.6940\n",
            "Epoch 22/100\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 0.9002 - accuracy: 0.6727 - val_loss: 0.8393 - val_accuracy: 0.6960\n",
            "Epoch 23/100\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 0.8994 - accuracy: 0.6714 - val_loss: 0.8403 - val_accuracy: 0.6948\n",
            "Epoch 24/100\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 0.8969 - accuracy: 0.6727 - val_loss: 0.8262 - val_accuracy: 0.7009\n",
            "Epoch 25/100\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 0.8896 - accuracy: 0.6779 - val_loss: 0.8269 - val_accuracy: 0.7038\n",
            "Epoch 26/100\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 0.8930 - accuracy: 0.6756 - val_loss: 0.8306 - val_accuracy: 0.6967\n",
            "Epoch 27/100\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 0.8877 - accuracy: 0.6764 - val_loss: 0.8350 - val_accuracy: 0.6922\n",
            "Epoch 28/100\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 0.8907 - accuracy: 0.6771 - val_loss: 0.8362 - val_accuracy: 0.6962\n",
            "Epoch 29/100\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 0.8806 - accuracy: 0.6805 - val_loss: 0.8354 - val_accuracy: 0.6917\n",
            "Epoch 30/100\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 0.8789 - accuracy: 0.6819 - val_loss: 0.8120 - val_accuracy: 0.7064\n",
            "Epoch 31/100\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 0.8790 - accuracy: 0.6811 - val_loss: 0.8117 - val_accuracy: 0.7087\n",
            "Epoch 32/100\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 0.8738 - accuracy: 0.6818 - val_loss: 0.8175 - val_accuracy: 0.7009\n",
            "Epoch 33/100\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 0.8725 - accuracy: 0.6839 - val_loss: 0.8167 - val_accuracy: 0.7042\n",
            "Epoch 34/100\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 0.8752 - accuracy: 0.6837 - val_loss: 0.8086 - val_accuracy: 0.7014\n",
            "Epoch 35/100\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 0.8726 - accuracy: 0.6844 - val_loss: 0.7941 - val_accuracy: 0.7114\n",
            "Epoch 36/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8702 - accuracy: 0.6808 - val_loss: 0.8065 - val_accuracy: 0.7069\n",
            "Epoch 37/100\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 0.8739 - accuracy: 0.6851 - val_loss: 0.8169 - val_accuracy: 0.6962\n",
            "Epoch 38/100\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 0.8700 - accuracy: 0.6871 - val_loss: 0.8093 - val_accuracy: 0.7072\n",
            "Epoch 39/100\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 0.8730 - accuracy: 0.6849 - val_loss: 0.8142 - val_accuracy: 0.6995\n",
            "Epoch 40/100\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 0.8723 - accuracy: 0.6841 - val_loss: 0.7915 - val_accuracy: 0.7097\n",
            "Epoch 41/100\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 0.8753 - accuracy: 0.6828 - val_loss: 0.7957 - val_accuracy: 0.7103\n",
            "Epoch 42/100\n",
            "48000/48000 [==============================] - 2s 35us/step - loss: 0.8711 - accuracy: 0.6873 - val_loss: 0.7893 - val_accuracy: 0.7122\n",
            "Epoch 43/100\n",
            "48000/48000 [==============================] - 2s 35us/step - loss: 0.8697 - accuracy: 0.6882 - val_loss: 0.7902 - val_accuracy: 0.7138\n",
            "Epoch 44/100\n",
            "48000/48000 [==============================] - 2s 35us/step - loss: 0.8692 - accuracy: 0.6830 - val_loss: 0.7992 - val_accuracy: 0.7093\n",
            "Epoch 45/100\n",
            "48000/48000 [==============================] - 2s 36us/step - loss: 0.8683 - accuracy: 0.6890 - val_loss: 0.7940 - val_accuracy: 0.7075\n",
            "Epoch 46/100\n",
            "48000/48000 [==============================] - 2s 36us/step - loss: 0.8655 - accuracy: 0.6883 - val_loss: 0.7991 - val_accuracy: 0.7076\n",
            "Epoch 47/100\n",
            "48000/48000 [==============================] - 2s 35us/step - loss: 0.8639 - accuracy: 0.6885 - val_loss: 0.7758 - val_accuracy: 0.7122\n",
            "Epoch 48/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8605 - accuracy: 0.6900 - val_loss: 0.7816 - val_accuracy: 0.7148\n",
            "Epoch 49/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8738 - accuracy: 0.6818 - val_loss: 0.7976 - val_accuracy: 0.7017\n",
            "Epoch 50/100\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 0.8691 - accuracy: 0.6861 - val_loss: 0.7860 - val_accuracy: 0.7132\n",
            "Epoch 51/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8634 - accuracy: 0.6870 - val_loss: 0.8054 - val_accuracy: 0.7052\n",
            "Epoch 52/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8567 - accuracy: 0.6908 - val_loss: 0.7798 - val_accuracy: 0.7179\n",
            "Epoch 53/100\n",
            "48000/48000 [==============================] - 2s 35us/step - loss: 0.8601 - accuracy: 0.6893 - val_loss: 0.7760 - val_accuracy: 0.7161\n",
            "Epoch 54/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8668 - accuracy: 0.6875 - val_loss: 0.7744 - val_accuracy: 0.7158\n",
            "Epoch 55/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8652 - accuracy: 0.6877 - val_loss: 0.8035 - val_accuracy: 0.7101\n",
            "Epoch 56/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8577 - accuracy: 0.6907 - val_loss: 0.7764 - val_accuracy: 0.7168\n",
            "Epoch 57/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8586 - accuracy: 0.6919 - val_loss: 0.7634 - val_accuracy: 0.7227\n",
            "Epoch 58/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8529 - accuracy: 0.6927 - val_loss: 0.7804 - val_accuracy: 0.7193\n",
            "Epoch 59/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8630 - accuracy: 0.6880 - val_loss: 0.7747 - val_accuracy: 0.7157\n",
            "Epoch 60/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8603 - accuracy: 0.6901 - val_loss: 0.7719 - val_accuracy: 0.7163\n",
            "Epoch 61/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8582 - accuracy: 0.6924 - val_loss: 0.7698 - val_accuracy: 0.7153\n",
            "Epoch 62/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8583 - accuracy: 0.6916 - val_loss: 0.7807 - val_accuracy: 0.7143\n",
            "Epoch 63/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8572 - accuracy: 0.6911 - val_loss: 0.7700 - val_accuracy: 0.7182\n",
            "Epoch 64/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8534 - accuracy: 0.6941 - val_loss: 0.7810 - val_accuracy: 0.7132\n",
            "Epoch 65/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8605 - accuracy: 0.6893 - val_loss: 0.7804 - val_accuracy: 0.7177\n",
            "Epoch 66/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8564 - accuracy: 0.6931 - val_loss: 0.7734 - val_accuracy: 0.7127\n",
            "Epoch 67/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8547 - accuracy: 0.6932 - val_loss: 0.7641 - val_accuracy: 0.7202\n",
            "Epoch 68/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8603 - accuracy: 0.6903 - val_loss: 0.7703 - val_accuracy: 0.7178\n",
            "Epoch 69/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8543 - accuracy: 0.6935 - val_loss: 0.7656 - val_accuracy: 0.7157\n",
            "Epoch 70/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8461 - accuracy: 0.6946 - val_loss: 0.7676 - val_accuracy: 0.7212\n",
            "Epoch 71/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8533 - accuracy: 0.6950 - val_loss: 0.7583 - val_accuracy: 0.7219\n",
            "Epoch 72/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8573 - accuracy: 0.6898 - val_loss: 0.7551 - val_accuracy: 0.7194\n",
            "Epoch 73/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8563 - accuracy: 0.6910 - val_loss: 0.7600 - val_accuracy: 0.7203\n",
            "Epoch 74/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8609 - accuracy: 0.6892 - val_loss: 0.7622 - val_accuracy: 0.7187\n",
            "Epoch 75/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8561 - accuracy: 0.6923 - val_loss: 0.7896 - val_accuracy: 0.7096\n",
            "Epoch 76/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8577 - accuracy: 0.6908 - val_loss: 0.7734 - val_accuracy: 0.7137\n",
            "Epoch 77/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8647 - accuracy: 0.6866 - val_loss: 0.7720 - val_accuracy: 0.7207\n",
            "Epoch 78/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8610 - accuracy: 0.6898 - val_loss: 0.7594 - val_accuracy: 0.7233\n",
            "Epoch 79/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8620 - accuracy: 0.6910 - val_loss: 0.7770 - val_accuracy: 0.7151\n",
            "Epoch 80/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8572 - accuracy: 0.6919 - val_loss: 0.7729 - val_accuracy: 0.7157\n",
            "Epoch 81/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8620 - accuracy: 0.6878 - val_loss: 0.7630 - val_accuracy: 0.7206\n",
            "Epoch 82/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8581 - accuracy: 0.6910 - val_loss: 0.7636 - val_accuracy: 0.7193\n",
            "Epoch 83/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8532 - accuracy: 0.6936 - val_loss: 0.7519 - val_accuracy: 0.7272\n",
            "Epoch 84/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8551 - accuracy: 0.6930 - val_loss: 0.7772 - val_accuracy: 0.7159\n",
            "Epoch 85/100\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 0.8624 - accuracy: 0.6917 - val_loss: 0.7694 - val_accuracy: 0.7187\n",
            "Epoch 86/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8656 - accuracy: 0.6908 - val_loss: 0.7698 - val_accuracy: 0.7197\n",
            "Epoch 87/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8646 - accuracy: 0.6894 - val_loss: 0.7554 - val_accuracy: 0.7238\n",
            "Epoch 88/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8588 - accuracy: 0.6897 - val_loss: 0.7656 - val_accuracy: 0.7218\n",
            "Epoch 89/100\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 0.8527 - accuracy: 0.6944 - val_loss: 0.7697 - val_accuracy: 0.7186\n",
            "Epoch 90/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8566 - accuracy: 0.6926 - val_loss: 0.7598 - val_accuracy: 0.7220\n",
            "Epoch 91/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8581 - accuracy: 0.6909 - val_loss: 0.7590 - val_accuracy: 0.7188\n",
            "Epoch 92/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8482 - accuracy: 0.6939 - val_loss: 0.7549 - val_accuracy: 0.7211\n",
            "Epoch 93/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8498 - accuracy: 0.6956 - val_loss: 0.7759 - val_accuracy: 0.7138\n",
            "Epoch 94/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8506 - accuracy: 0.6930 - val_loss: 0.7556 - val_accuracy: 0.7210\n",
            "Epoch 95/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8472 - accuracy: 0.6934 - val_loss: 0.7726 - val_accuracy: 0.7158\n",
            "Epoch 96/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8525 - accuracy: 0.6951 - val_loss: 0.7474 - val_accuracy: 0.7285\n",
            "Epoch 97/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8544 - accuracy: 0.6927 - val_loss: 0.7502 - val_accuracy: 0.7201\n",
            "Epoch 98/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8518 - accuracy: 0.6926 - val_loss: 0.7685 - val_accuracy: 0.7188\n",
            "Epoch 99/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8559 - accuracy: 0.6913 - val_loss: 0.7606 - val_accuracy: 0.7131\n",
            "Epoch 100/100\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.8556 - accuracy: 0.6922 - val_loss: 0.7521 - val_accuracy: 0.7193\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgMGH-4Gt8fi",
        "colab_type": "code",
        "outputId": "1a0125e8-ea49-4157-9556-515ba4cbe8b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "score = model.evaluate(test_features, y_test, verbose = 0)\n",
        "print('Test loss:',score[0])\n",
        "print('Test accuracy:',score[1])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.7405637618064881\n",
            "Test accuracy: 0.7346000075340271\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtTcaZ5Kugtm",
        "colab_type": "text"
      },
      "source": [
        "### 7. Results\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoDuzQ5mui2k",
        "colab_type": "code",
        "outputId": "656218b9-f6ff-4c69-a89a-9f55adeaf2fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "# plot the loss and accuracy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(accuracy)+1)\n",
        "\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.plot(epochs, accuracy, 'red', label='Training accuracy')\n",
        "plt.plot(epochs, val_accuracy, 'blue', label='Validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "plt.title('Training and validation loss')\n",
        "plt.plot(epochs, loss, 'red', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'blue', label='Validation loss')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}