{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG19HCNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO706vcGrXoTe5W3f+98vE2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdicherlaVenkataSai/H-CNNforfashionImageclassification/blob/master/VGG19HCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ROcAIK8Ro3j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "578f056a-bff9-4884-bd5e-263bc54c5bdb"
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Input\n",
        "from keras.initializers import he_normal\n",
        "from keras import optimizers\n",
        "from keras.callbacks import LearningRateScheduler, TensorBoard\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.utils import to_categorical\n",
        "from keras import backend as K"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VUzeFYqSJ4z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scheduler(epoch):\n",
        "  learning_rate_init = 0.001\n",
        "  if epoch > 42:\n",
        "    learning_rate_init = 0.0002\n",
        "  if epoch > 52:\n",
        "    learning_rate_init = 0.00005\n",
        "  return learning_rate_init"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcImVh4DSOlH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unpickle(filename):\n",
        "  file = os.path.join(data_dir, filename)\n",
        "  with open(file, 'rb') as fo:\n",
        "    dict = pickle.load(fo, encoding='bytes')\n",
        "  return dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fo8Vte6QSQo7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LossWeightsModifier(keras.callbacks.Callback):\n",
        "  def __init__(self, alpha, beta, gamma):\n",
        "    self.alpha = alpha\n",
        "    self.beta = beta\n",
        "    self.gamma = gamma\n",
        "    # customize your behavior\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if epoch == 15:\n",
        "      K.set_value(self.alpha, 0.1)\n",
        "      K.set_value(self.beta, 0.8)\n",
        "      K.set_value(self.gamma, 0.1)\n",
        "    if epoch == 25:\n",
        "      K.set_value(self.alpha, 0.1)\n",
        "      K.set_value(self.beta, 0.2)\n",
        "      K.set_value(self.gamma, 0.7)\n",
        "    if epoch == 35:\n",
        "      K.set_value(self.alpha, 0)\n",
        "      K.set_value(self.beta, 0)\n",
        "      K.set_value(self.gamma, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHRdAijgSWNq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "height, width = 28, 28\n",
        "channel = 1\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    input_shape = (channel, height, width)\n",
        "else:\n",
        "    input_shape = (height, width, channel)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RogXJi1LSal1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_size = 60000\n",
        "test_size = 10000\n",
        "\n",
        "coarse1_classes = 2\n",
        "\n",
        "coarse2_classes = 6\n",
        "\n",
        "num_classes  = 10\n",
        "\n",
        "batch_size   = 128\n",
        "epochs       = 60"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8L6W9zD_ShYd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log_filepath = './tb_log_vgg19_hierarchy_dynamic/'\n",
        "weights_store_filepath = './vgg19_weights_hierarchy_dynamic/'\n",
        "retrain_id = '101'\n",
        "model_name = 'weights_vgg16_fashionmnist'+retrain_id+'.h5'\n",
        "model_path = os.path.join(weights_store_filepath, model_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eaw3ksGjSpL-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8cb6030b-b2c3-457f-f7ed-5c41e1f84091"
      },
      "source": [
        "WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels.h5'\n",
        "weights_path = get_file('vgg19_weights_tf_dim_ordering_tf_kernels.h5',\n",
        "                         WEIGHTS_PATH,\n",
        "                         cache_subdir='models')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels.h5\n",
            "574717952/574710816 [==============================] - 53s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2z3Kwp9SwQe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "0bed4b5e-84f1-4c21-af3a-e06d1a26bac6"
      },
      "source": [
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = keras.datasets.fashion_mnist.load_data()\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "class_names_c1 = ['Clothes', 'Goods']\n",
        "class_names_c2 = ['Tops', 'Bottoms', 'Dresses', 'Outers', 'Accessories', 'Shoes']"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 9us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 4s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 2s 1us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbgOKEQVSz4n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c2_to_c1 = {0:0, 1:0, 2:0, 3:0, 4:1, 5:1}\n",
        "fine_to_c2 = {0:0, 1:1, 2:0, 3:2, 4:3, 5:5, 6:0, 7:5, 8:4, 9:5}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeN3sb4NS256",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_mappings(mapping, source, dest):\n",
        "    for k,v in mapping.items():\n",
        "        print(source[k], \"->\", dest[v])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54fs6L7JS4sj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "0189148e-a9e2-4d18-a7cd-e31ba79958a0"
      },
      "source": [
        "print_mappings(c2_to_c1, class_names_c2, class_names_c1)\n",
        "print(\"-\"*10)\n",
        "print_mappings(fine_to_c2, class_names, class_names_c2)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tops -> Clothes\n",
            "Bottoms -> Clothes\n",
            "Dresses -> Clothes\n",
            "Outers -> Clothes\n",
            "Accessories -> Goods\n",
            "Shoes -> Goods\n",
            "----------\n",
            "T-shirt/top -> Tops\n",
            "Trouser -> Bottoms\n",
            "Pullover -> Tops\n",
            "Dress -> Dresses\n",
            "Coat -> Outers\n",
            "Sandal -> Shoes\n",
            "Shirt -> Tops\n",
            "Sneaker -> Shoes\n",
            "Bag -> Accessories\n",
            "Ankle boot -> Shoes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRu_S33ZS7IU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "67a35fc4-11f6-45eb-92e0-52f60385d5af"
      },
      "source": [
        "train_images.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Khz2Ip6iS9YQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "05b0f89c-7d6d-4755-a0d6-9bcec24c8949"
      },
      "source": [
        "train_labels_fine = to_categorical(train_labels)\n",
        "train_labels_fine.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40YDy2ggS_ZX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e177b105-a06e-4bea-fa9d-0cc73a82daab"
      },
      "source": [
        "test_labels_fine = to_categorical(test_labels)\n",
        "test_labels_fine.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCQmimNhTBjW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "92cc3bca-f881-4e51-c406-95be283f2e1a"
      },
      "source": [
        "train_labels_c2_index = [fine_to_c2[i] for i in train_labels]\n",
        "train_labels_c2 = to_categorical(train_labels_c2_index)\n",
        "train_labels_c2.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVuPp-CTTFBr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5f0f5f7a-a788-42ec-d011-edff4caabe2c"
      },
      "source": [
        "test_labels_c2_index = [fine_to_c2[i] for i in test_labels]\n",
        "test_labels_c2 = to_categorical(test_labels_c2_index)\n",
        "test_labels_c2.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44KM5uKKTHH7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e15584b1-fc4b-43c8-dd84-7225d02585bd"
      },
      "source": [
        "train_labels_c1_index = [c2_to_c1[i] for i in train_labels_c2_index]\n",
        "train_labels_c1 = to_categorical(train_labels_c1_index)\n",
        "train_labels_c1.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEv0fduhTJoM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "627da23d-2933-41ba-ef47-4b86fdab98c4"
      },
      "source": [
        "test_labels_c1_index = [c2_to_c1[i] for i in test_labels_c2_index]\n",
        "test_labels_c1 = to_categorical(test_labels_c1_index)\n",
        "test_labels_c1.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foamauGcTMCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = train_images[..., np.newaxis]\n",
        "x_test = test_images[..., np.newaxis]\n",
        "\n",
        "y_train = train_labels_fine\n",
        "y_test = test_labels_fine\n",
        "\n",
        "y_c1_train = train_labels_c1\n",
        "y_c1_test = test_labels_c1\n",
        "\n",
        "y_c2_train = train_labels_c2\n",
        "y_c2_test = test_labels_c2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INOsQkxYTOdp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "53fc46ec-383b-4083-daf8-1da1bf6c16ae"
      },
      "source": [
        "print(\"x_train shape: \", x_train.shape)\n",
        "print(\"x_test shape: \", x_test.shape)\n",
        "\n",
        "print(\"y_train shape: \", y_train.shape)\n",
        "print(\"y_test shape: \", y_test.shape)\n",
        "print(\"y_c1_train shape: \", y_c1_train.shape)\n",
        "print(\"y_c1_test shape: \", y_c1_test.shape)\n",
        "print(\"y_c2_train shape: \", y_c2_train.shape)\n",
        "print(\"y_c2_test shape: \", y_c2_test.shape)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape:  (60000, 28, 28, 1)\n",
            "x_test shape:  (10000, 28, 28, 1)\n",
            "y_train shape:  (60000, 10)\n",
            "y_test shape:  (10000, 10)\n",
            "y_c1_train shape:  (60000, 2)\n",
            "y_c1_test shape:  (10000, 2)\n",
            "y_c2_train shape:  (60000, 6)\n",
            "y_c2_test shape:  (10000, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNSqfsvSTSPX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "89a7523b-1184-4e69-b8d6-61409d4dd3f9"
      },
      "source": [
        "alpha = K.variable(value=0.98, dtype=\"float32\", name=\"alpha\") \n",
        "beta = K.variable(value=0.01, dtype=\"float32\", name=\"beta\") \n",
        "gamma = K.variable(value=0.01, dtype=\"float32\", name=\"gamma\") \n",
        "\n",
        "img_input = Input(shape=input_shape, name='input')\n",
        "img_input"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'input:0' shape=(None, 28, 28, 1) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbD-VUbjTVO6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#block 1 \n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(img_input)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
        "\n",
        "#block 2 \n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
        "\n",
        "#coarse 1 \n",
        "c_1_bch = Flatten(name='c1_flatten')(x)\n",
        "c_1_bch = Dense(256, activation='relu')(c_1_bch)\n",
        "c_1_bch = BatchNormalization()(c_1_bch)\n",
        "c_1_bch = Dropout(0.5)(c_1_bch)\n",
        "c_1_bch = Dense(256, activation='relu')(c_1_bch)\n",
        "c_1_bch = BatchNormalization()(c_1_bch)\n",
        "c_1_bch = Dropout(0.5)(c_1_bch)\n",
        "c_1_pred = Dense(coarse1_classes, activation='softmax')(c_1_bch)\n",
        "\n",
        "#block 3 \n",
        "x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
        "\n",
        "#coarse 2\n",
        "c_2_bch = Flatten(name='c2_flatten')(x)\n",
        "c_2_bch = Dense(1024, activation='relu')(c_2_bch)\n",
        "c_2_bch = BatchNormalization()(c_2_bch)\n",
        "c_2_bch = Dropout(0.5)(c_2_bch)\n",
        "c_2_bch = Dense(1024, activation='relu')(c_2_bch)\n",
        "c_2_bch = BatchNormalization()(c_2_bch)\n",
        "c_2_bch = Dropout(0.5)(c_2_bch)\n",
        "c_2_pred = Dense(coarse2_classes, activation='softmax')(c_2_bch)\n",
        "\n",
        "#block 4 \n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
        "\n",
        "\n",
        "#block 5\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "#fine \n",
        "x = Flatten(name='flatten')(x)\n",
        "x = Dense(4096, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(4096, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "fine_pred = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "\n",
        "model = Model(img_input, [c_1_pred, c_2_pred, fine_pred], name='vgg19_hierarchy')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOvCqI04U2mm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b18e1d0b-2c78-41f4-8e69-01698626ca1e"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg19_hierarchy\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input (InputLayer)              (None, 28, 28, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 28, 28, 64)   640         input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 28, 28, 64)   256         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 28, 28, 64)   36928       batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 28, 28, 64)   256         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 14, 14, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 14, 14, 128)  73856       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 14, 14, 128)  512         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 14, 14, 128)  147584      batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 14, 14, 128)  512         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 128)    0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 7, 7, 256)    295168      max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 7, 7, 256)    1024        conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 7, 7, 256)    590080      batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 7, 7, 256)    1024        conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 7, 7, 256)    590080      batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 7, 7, 256)    1024        conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 7, 7, 256)    590080      batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 7, 7, 256)    1024        conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 256)    0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 3, 3, 512)    1180160     max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 3, 3, 512)    2048        conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 3, 3, 512)    2359808     batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 3, 3, 512)    2048        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 3, 3, 512)    2359808     batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 3, 3, 512)    2048        conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 3, 3, 512)    2359808     batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 3, 3, 512)    2048        conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 1, 1, 512)    0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 1, 1, 512)    2359808     max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 1, 1, 512)    2048        conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 1, 1, 512)    2359808     batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 1, 1, 512)    2048        conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 1, 1, 512)    2359808     batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 1, 1, 512)    2048        conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 1, 1, 512)    2359808     batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 1, 1, 512)    2048        conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "c1_flatten (Flatten)            (None, 6272)         0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "c2_flatten (Flatten)            (None, 2304)         0           max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 512)          0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 256)          1605888     c1_flatten[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1024)         2360320     c2_flatten[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 4096)         2101248     flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 256)          1024        dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 1024)         4096        dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 4096)         16384       dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 256)          0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 1024)         0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 4096)         0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 256)          65792       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 1024)         1049600     dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 4096)         16781312    dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 256)          1024        dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 1024)         4096        dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 4096)         16384       dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 256)          0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 1024)         0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 4096)         0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            514         dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 6)            6150        dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 10)           40970       dropout_6[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 44,100,050\n",
            "Trainable params: 44,067,538\n",
            "Non-trainable params: 32,512\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-2unRQHU9UA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1120c879-4125-4562-b7b3-8356401be9dd"
      },
      "source": [
        "sgd = optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer=sgd, \n",
        "              loss_weights=[alpha, beta, gamma], \n",
        "              # optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "tb_cb = TensorBoard(log_dir=log_filepath, histogram_freq=0)\n",
        "change_lr = LearningRateScheduler(scheduler)\n",
        "change_lw = LossWeightsModifier(alpha, beta, gamma)\n",
        "cbks = [change_lr, tb_cb, change_lw]\n",
        "\n",
        "history = model.fit(x_train, [y_c1_train, y_c2_train, y_train],\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          callbacks=cbks,\n",
        "          validation_data=(x_test, [y_c1_test, y_c2_test, y_test]))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/60\n",
            "60000/60000 [==============================] - 94s 2ms/step - loss: 0.1070 - dense_3_loss: 0.0652 - dense_6_loss: 1.5178 - dense_9_loss: 2.7964 - dense_3_accuracy: 0.9786 - dense_6_accuracy: 0.5157 - dense_9_accuracy: 0.2403 - val_loss: 0.0444 - val_dense_3_loss: 0.0251 - val_dense_6_loss: 0.5361 - val_dense_9_loss: 1.4303 - val_dense_3_accuracy: 0.9923 - val_dense_6_accuracy: 0.8141 - val_dense_9_accuracy: 0.5142\n",
            "Epoch 2/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0476 - dense_3_loss: 0.0265 - dense_6_loss: 0.7401 - dense_9_loss: 1.4183 - dense_3_accuracy: 0.9927 - dense_6_accuracy: 0.7511 - dense_9_accuracy: 0.5644 - val_loss: 0.0276 - val_dense_3_loss: 0.0160 - val_dense_6_loss: 0.3919 - val_dense_9_loss: 0.7841 - val_dense_3_accuracy: 0.9957 - val_dense_6_accuracy: 0.8638 - val_dense_9_accuracy: 0.7314\n",
            "Epoch 3/60\n",
            "60000/60000 [==============================] - 83s 1ms/step - loss: 0.0370 - dense_3_loss: 0.0211 - dense_6_loss: 0.5902 - dense_9_loss: 1.0469 - dense_3_accuracy: 0.9938 - dense_6_accuracy: 0.8062 - dense_9_accuracy: 0.6798 - val_loss: 0.0252 - val_dense_3_loss: 0.0151 - val_dense_6_loss: 0.3458 - val_dense_9_loss: 0.6798 - val_dense_3_accuracy: 0.9953 - val_dense_6_accuracy: 0.8766 - val_dense_9_accuracy: 0.7677\n",
            "Epoch 4/60\n",
            "60000/60000 [==============================] - 83s 1ms/step - loss: 0.0312 - dense_3_loss: 0.0175 - dense_6_loss: 0.5150 - dense_9_loss: 0.8876 - dense_3_accuracy: 0.9950 - dense_6_accuracy: 0.8320 - dense_9_accuracy: 0.7260 - val_loss: 0.0224 - val_dense_3_loss: 0.0131 - val_dense_6_loss: 0.3228 - val_dense_9_loss: 0.6167 - val_dense_3_accuracy: 0.9962 - val_dense_6_accuracy: 0.8858 - val_dense_9_accuracy: 0.7822\n",
            "Epoch 5/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0261 - dense_3_loss: 0.0140 - dense_6_loss: 0.4615 - dense_9_loss: 0.7790 - dense_3_accuracy: 0.9958 - dense_6_accuracy: 0.8467 - dense_9_accuracy: 0.7555 - val_loss: 0.0200 - val_dense_3_loss: 0.0115 - val_dense_6_loss: 0.2879 - val_dense_9_loss: 0.5683 - val_dense_3_accuracy: 0.9964 - val_dense_6_accuracy: 0.8962 - val_dense_9_accuracy: 0.8024\n",
            "Epoch 6/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0235 - dense_3_loss: 0.0122 - dense_6_loss: 0.4338 - dense_9_loss: 0.7174 - dense_3_accuracy: 0.9964 - dense_6_accuracy: 0.8565 - dense_9_accuracy: 0.7735 - val_loss: 0.0189 - val_dense_3_loss: 0.0108 - val_dense_6_loss: 0.2769 - val_dense_9_loss: 0.5393 - val_dense_3_accuracy: 0.9972 - val_dense_6_accuracy: 0.9028 - val_dense_9_accuracy: 0.8196\n",
            "Epoch 7/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0202 - dense_3_loss: 0.0097 - dense_6_loss: 0.4066 - dense_9_loss: 0.6670 - dense_3_accuracy: 0.9970 - dense_6_accuracy: 0.8647 - dense_9_accuracy: 0.7893 - val_loss: 0.0172 - val_dense_3_loss: 0.0096 - val_dense_6_loss: 0.2647 - val_dense_9_loss: 0.5069 - val_dense_3_accuracy: 0.9973 - val_dense_6_accuracy: 0.9039 - val_dense_9_accuracy: 0.8273\n",
            "Epoch 8/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0190 - dense_3_loss: 0.0093 - dense_6_loss: 0.3761 - dense_9_loss: 0.6146 - dense_3_accuracy: 0.9972 - dense_6_accuracy: 0.8744 - dense_9_accuracy: 0.8063 - val_loss: 0.0167 - val_dense_3_loss: 0.0093 - val_dense_6_loss: 0.2545 - val_dense_9_loss: 0.4874 - val_dense_3_accuracy: 0.9972 - val_dense_6_accuracy: 0.9082 - val_dense_9_accuracy: 0.8333\n",
            "Epoch 9/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0170 - dense_3_loss: 0.0078 - dense_6_loss: 0.3647 - dense_9_loss: 0.5772 - dense_3_accuracy: 0.9977 - dense_6_accuracy: 0.8774 - dense_9_accuracy: 0.8166 - val_loss: 0.0177 - val_dense_3_loss: 0.0104 - val_dense_6_loss: 0.2554 - val_dense_9_loss: 0.4894 - val_dense_3_accuracy: 0.9968 - val_dense_6_accuracy: 0.9093 - val_dense_9_accuracy: 0.8328\n",
            "Epoch 10/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0154 - dense_3_loss: 0.0065 - dense_6_loss: 0.3495 - dense_9_loss: 0.5545 - dense_3_accuracy: 0.9980 - dense_6_accuracy: 0.8826 - dense_9_accuracy: 0.8242 - val_loss: 0.0160 - val_dense_3_loss: 0.0090 - val_dense_6_loss: 0.2437 - val_dense_9_loss: 0.4698 - val_dense_3_accuracy: 0.9975 - val_dense_6_accuracy: 0.9119 - val_dense_9_accuracy: 0.8408\n",
            "Epoch 11/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0139 - dense_3_loss: 0.0055 - dense_6_loss: 0.3333 - dense_9_loss: 0.5238 - dense_3_accuracy: 0.9983 - dense_6_accuracy: 0.8876 - dense_9_accuracy: 0.8328 - val_loss: 0.0164 - val_dense_3_loss: 0.0097 - val_dense_6_loss: 0.2334 - val_dense_9_loss: 0.4500 - val_dense_3_accuracy: 0.9969 - val_dense_6_accuracy: 0.9158 - val_dense_9_accuracy: 0.8463\n",
            "Epoch 12/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0133 - dense_3_loss: 0.0052 - dense_6_loss: 0.3241 - dense_9_loss: 0.4987 - dense_3_accuracy: 0.9983 - dense_6_accuracy: 0.8895 - dense_9_accuracy: 0.8401 - val_loss: 0.0155 - val_dense_3_loss: 0.0089 - val_dense_6_loss: 0.2282 - val_dense_9_loss: 0.4460 - val_dense_3_accuracy: 0.9974 - val_dense_6_accuracy: 0.9183 - val_dense_9_accuracy: 0.8539\n",
            "Epoch 13/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0127 - dense_3_loss: 0.0050 - dense_6_loss: 0.3145 - dense_9_loss: 0.4684 - dense_3_accuracy: 0.9985 - dense_6_accuracy: 0.8925 - dense_9_accuracy: 0.8490 - val_loss: 0.0156 - val_dense_3_loss: 0.0090 - val_dense_6_loss: 0.2261 - val_dense_9_loss: 0.4389 - val_dense_3_accuracy: 0.9972 - val_dense_6_accuracy: 0.9189 - val_dense_9_accuracy: 0.8549\n",
            "Epoch 14/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0113 - dense_3_loss: 0.0037 - dense_6_loss: 0.3103 - dense_9_loss: 0.4554 - dense_3_accuracy: 0.9988 - dense_6_accuracy: 0.8948 - dense_9_accuracy: 0.8527 - val_loss: 0.0160 - val_dense_3_loss: 0.0096 - val_dense_6_loss: 0.2211 - val_dense_9_loss: 0.4331 - val_dense_3_accuracy: 0.9972 - val_dense_6_accuracy: 0.9177 - val_dense_9_accuracy: 0.8589\n",
            "Epoch 15/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0109 - dense_3_loss: 0.0037 - dense_6_loss: 0.2947 - dense_9_loss: 0.4344 - dense_3_accuracy: 0.9987 - dense_6_accuracy: 0.8995 - dense_9_accuracy: 0.8605 - val_loss: 0.0148 - val_dense_3_loss: 0.0085 - val_dense_6_loss: 0.2193 - val_dense_9_loss: 0.4242 - val_dense_3_accuracy: 0.9972 - val_dense_6_accuracy: 0.9214 - val_dense_9_accuracy: 0.8608\n",
            "Epoch 16/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0102 - dense_3_loss: 0.0031 - dense_6_loss: 0.2923 - dense_9_loss: 0.4214 - dense_3_accuracy: 0.9991 - dense_6_accuracy: 0.9000 - dense_9_accuracy: 0.8645 - val_loss: 0.0151 - val_dense_3_loss: 0.0090 - val_dense_6_loss: 0.2164 - val_dense_9_loss: 0.4075 - val_dense_3_accuracy: 0.9977 - val_dense_6_accuracy: 0.9216 - val_dense_9_accuracy: 0.8632\n",
            "Epoch 17/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.2842 - dense_3_loss: 0.0100 - dense_6_loss: 0.2801 - dense_9_loss: 0.5912 - dense_3_accuracy: 0.9968 - dense_6_accuracy: 0.9049 - dense_9_accuracy: 0.8117 - val_loss: 0.1929 - val_dense_3_loss: 0.0111 - val_dense_6_loss: 0.1835 - val_dense_9_loss: 0.4366 - val_dense_3_accuracy: 0.9967 - val_dense_6_accuracy: 0.9347 - val_dense_9_accuracy: 0.8519\n",
            "Epoch 18/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.2062 - dense_3_loss: 0.0112 - dense_6_loss: 0.1981 - dense_9_loss: 0.4656 - dense_3_accuracy: 0.9966 - dense_6_accuracy: 0.9306 - dense_9_accuracy: 0.8500 - val_loss: 0.1714 - val_dense_3_loss: 0.0121 - val_dense_6_loss: 0.1615 - val_dense_9_loss: 0.4005 - val_dense_3_accuracy: 0.9970 - val_dense_6_accuracy: 0.9426 - val_dense_9_accuracy: 0.8700\n",
            "Epoch 19/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.1705 - dense_3_loss: 0.0110 - dense_6_loss: 0.1635 - dense_9_loss: 0.3866 - dense_3_accuracy: 0.9966 - dense_6_accuracy: 0.9406 - dense_9_accuracy: 0.8729 - val_loss: 0.1523 - val_dense_3_loss: 0.0115 - val_dense_6_loss: 0.1439 - val_dense_9_loss: 0.3595 - val_dense_3_accuracy: 0.9966 - val_dense_6_accuracy: 0.9485 - val_dense_9_accuracy: 0.8791\n",
            "Epoch 20/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.1413 - dense_3_loss: 0.0106 - dense_6_loss: 0.1335 - dense_9_loss: 0.3352 - dense_3_accuracy: 0.9967 - dense_6_accuracy: 0.9520 - dense_9_accuracy: 0.8906 - val_loss: 0.1333 - val_dense_3_loss: 0.0097 - val_dense_6_loss: 0.1271 - val_dense_9_loss: 0.2999 - val_dense_3_accuracy: 0.9973 - val_dense_6_accuracy: 0.9544 - val_dense_9_accuracy: 0.8988\n",
            "Epoch 21/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.1263 - dense_3_loss: 0.0100 - dense_6_loss: 0.1189 - dense_9_loss: 0.3014 - dense_3_accuracy: 0.9971 - dense_6_accuracy: 0.9569 - dense_9_accuracy: 0.8993 - val_loss: 0.1308 - val_dense_3_loss: 0.0093 - val_dense_6_loss: 0.1276 - val_dense_9_loss: 0.2814 - val_dense_3_accuracy: 0.9972 - val_dense_6_accuracy: 0.9557 - val_dense_9_accuracy: 0.8997\n",
            "Epoch 22/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.1087 - dense_3_loss: 0.0090 - dense_6_loss: 0.1010 - dense_9_loss: 0.2700 - dense_3_accuracy: 0.9973 - dense_6_accuracy: 0.9627 - dense_9_accuracy: 0.9105 - val_loss: 0.1345 - val_dense_3_loss: 0.0091 - val_dense_6_loss: 0.1259 - val_dense_9_loss: 0.3262 - val_dense_3_accuracy: 0.9972 - val_dense_6_accuracy: 0.9541 - val_dense_9_accuracy: 0.8944\n",
            "Epoch 23/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0976 - dense_3_loss: 0.0083 - dense_6_loss: 0.0911 - dense_9_loss: 0.2386 - dense_3_accuracy: 0.9973 - dense_6_accuracy: 0.9667 - dense_9_accuracy: 0.9200 - val_loss: 0.1208 - val_dense_3_loss: 0.0092 - val_dense_6_loss: 0.1140 - val_dense_9_loss: 0.2869 - val_dense_3_accuracy: 0.9972 - val_dense_6_accuracy: 0.9600 - val_dense_9_accuracy: 0.9032\n",
            "Epoch 24/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0858 - dense_3_loss: 0.0087 - dense_6_loss: 0.0784 - dense_9_loss: 0.2222 - dense_3_accuracy: 0.9972 - dense_6_accuracy: 0.9713 - dense_9_accuracy: 0.9233 - val_loss: 0.1206 - val_dense_3_loss: 0.0088 - val_dense_6_loss: 0.1148 - val_dense_9_loss: 0.2836 - val_dense_3_accuracy: 0.9974 - val_dense_6_accuracy: 0.9609 - val_dense_9_accuracy: 0.9075\n",
            "Epoch 25/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0732 - dense_3_loss: 0.0090 - dense_6_loss: 0.0662 - dense_9_loss: 0.1934 - dense_3_accuracy: 0.9973 - dense_6_accuracy: 0.9757 - dense_9_accuracy: 0.9337 - val_loss: 0.1337 - val_dense_3_loss: 0.0095 - val_dense_6_loss: 0.1274 - val_dense_9_loss: 0.3111 - val_dense_3_accuracy: 0.9968 - val_dense_6_accuracy: 0.9562 - val_dense_9_accuracy: 0.9036\n",
            "Epoch 26/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0664 - dense_3_loss: 0.0085 - dense_6_loss: 0.0600 - dense_9_loss: 0.1757 - dense_3_accuracy: 0.9974 - dense_6_accuracy: 0.9783 - dense_9_accuracy: 0.9399 - val_loss: 0.2047 - val_dense_3_loss: 0.0093 - val_dense_6_loss: 0.2026 - val_dense_9_loss: 0.4157 - val_dense_3_accuracy: 0.9971 - val_dense_6_accuracy: 0.9376 - val_dense_9_accuracy: 0.8797\n",
            "Epoch 27/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.2135 - dense_3_loss: 0.0099 - dense_6_loss: 0.0784 - dense_9_loss: 0.2812 - dense_3_accuracy: 0.9970 - dense_6_accuracy: 0.9707 - dense_9_accuracy: 0.9064 - val_loss: 0.2487 - val_dense_3_loss: 0.0105 - val_dense_6_loss: 0.1297 - val_dense_9_loss: 0.3157 - val_dense_3_accuracy: 0.9966 - val_dense_6_accuracy: 0.9574 - val_dense_9_accuracy: 0.8976\n",
            "Epoch 28/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.1676 - dense_3_loss: 0.0088 - dense_6_loss: 0.0749 - dense_9_loss: 0.2168 - dense_3_accuracy: 0.9973 - dense_6_accuracy: 0.9728 - dense_9_accuracy: 0.9268 - val_loss: 0.2430 - val_dense_3_loss: 0.0099 - val_dense_6_loss: 0.1258 - val_dense_9_loss: 0.3091 - val_dense_3_accuracy: 0.9970 - val_dense_6_accuracy: 0.9590 - val_dense_9_accuracy: 0.9017\n",
            "Epoch 29/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.1305 - dense_3_loss: 0.0087 - dense_6_loss: 0.0615 - dense_9_loss: 0.1675 - dense_3_accuracy: 0.9975 - dense_6_accuracy: 0.9772 - dense_9_accuracy: 0.9428 - val_loss: 0.2086 - val_dense_3_loss: 0.0090 - val_dense_6_loss: 0.1210 - val_dense_9_loss: 0.2647 - val_dense_3_accuracy: 0.9970 - val_dense_6_accuracy: 0.9608 - val_dense_9_accuracy: 0.9171\n",
            "Epoch 30/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.1070 - dense_3_loss: 0.0086 - dense_6_loss: 0.0561 - dense_9_loss: 0.1357 - dense_3_accuracy: 0.9973 - dense_6_accuracy: 0.9797 - dense_9_accuracy: 0.9525 - val_loss: 0.2215 - val_dense_3_loss: 0.0094 - val_dense_6_loss: 0.1276 - val_dense_9_loss: 0.2803 - val_dense_3_accuracy: 0.9973 - val_dense_6_accuracy: 0.9576 - val_dense_9_accuracy: 0.9138\n",
            "Epoch 31/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0863 - dense_3_loss: 0.0090 - dense_6_loss: 0.0486 - dense_9_loss: 0.1081 - dense_3_accuracy: 0.9971 - dense_6_accuracy: 0.9828 - dense_9_accuracy: 0.9618 - val_loss: 0.2467 - val_dense_3_loss: 0.0091 - val_dense_6_loss: 0.1326 - val_dense_9_loss: 0.3150 - val_dense_3_accuracy: 0.9972 - val_dense_6_accuracy: 0.9584 - val_dense_9_accuracy: 0.9084\n",
            "Epoch 32/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0704 - dense_3_loss: 0.0083 - dense_6_loss: 0.0452 - dense_9_loss: 0.0864 - dense_3_accuracy: 0.9974 - dense_6_accuracy: 0.9838 - dense_9_accuracy: 0.9701 - val_loss: 0.2446 - val_dense_3_loss: 0.0085 - val_dense_6_loss: 0.1179 - val_dense_9_loss: 0.3203 - val_dense_3_accuracy: 0.9979 - val_dense_6_accuracy: 0.9609 - val_dense_9_accuracy: 0.9132\n",
            "Epoch 33/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0606 - dense_3_loss: 0.0070 - dense_6_loss: 0.0419 - dense_9_loss: 0.0736 - dense_3_accuracy: 0.9980 - dense_6_accuracy: 0.9852 - dense_9_accuracy: 0.9747 - val_loss: 0.2667 - val_dense_3_loss: 0.0093 - val_dense_6_loss: 0.1244 - val_dense_9_loss: 0.3445 - val_dense_3_accuracy: 0.9976 - val_dense_6_accuracy: 0.9608 - val_dense_9_accuracy: 0.9130\n",
            "Epoch 34/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0508 - dense_3_loss: 0.0085 - dense_6_loss: 0.0382 - dense_9_loss: 0.0604 - dense_3_accuracy: 0.9974 - dense_6_accuracy: 0.9863 - dense_9_accuracy: 0.9789 - val_loss: 0.3060 - val_dense_3_loss: 0.0084 - val_dense_6_loss: 0.1546 - val_dense_9_loss: 0.3959 - val_dense_3_accuracy: 0.9972 - val_dense_6_accuracy: 0.9527 - val_dense_9_accuracy: 0.9032\n",
            "Epoch 35/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0476 - dense_3_loss: 0.0078 - dense_6_loss: 0.0379 - dense_9_loss: 0.0560 - dense_3_accuracy: 0.9975 - dense_6_accuracy: 0.9864 - dense_9_accuracy: 0.9808 - val_loss: 0.2707 - val_dense_3_loss: 0.0095 - val_dense_6_loss: 0.1267 - val_dense_9_loss: 0.3549 - val_dense_3_accuracy: 0.9976 - val_dense_6_accuracy: 0.9602 - val_dense_9_accuracy: 0.9139\n",
            "Epoch 36/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0370 - dense_3_loss: 0.0073 - dense_6_loss: 0.0326 - dense_9_loss: 0.0424 - dense_3_accuracy: 0.9978 - dense_6_accuracy: 0.9881 - dense_9_accuracy: 0.9853 - val_loss: 0.2620 - val_dense_3_loss: 0.0092 - val_dense_6_loss: 0.1256 - val_dense_9_loss: 0.3418 - val_dense_3_accuracy: 0.9974 - val_dense_6_accuracy: 0.9617 - val_dense_9_accuracy: 0.9235\n",
            "Epoch 37/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0739 - dense_3_loss: 0.0078 - dense_6_loss: 0.0430 - dense_9_loss: 0.0739 - dense_3_accuracy: 0.9976 - dense_6_accuracy: 0.9844 - dense_9_accuracy: 0.9749 - val_loss: 0.3506 - val_dense_3_loss: 0.0088 - val_dense_6_loss: 0.1334 - val_dense_9_loss: 0.3539 - val_dense_3_accuracy: 0.9975 - val_dense_6_accuracy: 0.9570 - val_dense_9_accuracy: 0.9133\n",
            "Epoch 38/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0689 - dense_3_loss: 0.0078 - dense_6_loss: 0.0458 - dense_9_loss: 0.0689 - dense_3_accuracy: 0.9977 - dense_6_accuracy: 0.9833 - dense_9_accuracy: 0.9765 - val_loss: 0.3355 - val_dense_3_loss: 0.0084 - val_dense_6_loss: 0.1443 - val_dense_9_loss: 0.3406 - val_dense_3_accuracy: 0.9977 - val_dense_6_accuracy: 0.9574 - val_dense_9_accuracy: 0.9112\n",
            "Epoch 39/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0592 - dense_3_loss: 0.0088 - dense_6_loss: 0.0448 - dense_9_loss: 0.0592 - dense_3_accuracy: 0.9973 - dense_6_accuracy: 0.9845 - dense_9_accuracy: 0.9796 - val_loss: 0.3204 - val_dense_3_loss: 0.0088 - val_dense_6_loss: 0.1281 - val_dense_9_loss: 0.3251 - val_dense_3_accuracy: 0.9972 - val_dense_6_accuracy: 0.9610 - val_dense_9_accuracy: 0.9184\n",
            "Epoch 40/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0549 - dense_3_loss: 0.0091 - dense_6_loss: 0.0464 - dense_9_loss: 0.0549 - dense_3_accuracy: 0.9971 - dense_6_accuracy: 0.9836 - dense_9_accuracy: 0.9811 - val_loss: 0.3355 - val_dense_3_loss: 0.0099 - val_dense_6_loss: 0.1342 - val_dense_9_loss: 0.3342 - val_dense_3_accuracy: 0.9969 - val_dense_6_accuracy: 0.9594 - val_dense_9_accuracy: 0.9181\n",
            "Epoch 41/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0455 - dense_3_loss: 0.0089 - dense_6_loss: 0.0441 - dense_9_loss: 0.0455 - dense_3_accuracy: 0.9971 - dense_6_accuracy: 0.9839 - dense_9_accuracy: 0.9846 - val_loss: 0.3853 - val_dense_3_loss: 0.0080 - val_dense_6_loss: 0.1374 - val_dense_9_loss: 0.3853 - val_dense_3_accuracy: 0.9978 - val_dense_6_accuracy: 0.9578 - val_dense_9_accuracy: 0.9139\n",
            "Epoch 42/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0394 - dense_3_loss: 0.0088 - dense_6_loss: 0.0416 - dense_9_loss: 0.0394 - dense_3_accuracy: 0.9971 - dense_6_accuracy: 0.9853 - dense_9_accuracy: 0.9871 - val_loss: 0.3553 - val_dense_3_loss: 0.0087 - val_dense_6_loss: 0.1301 - val_dense_9_loss: 0.3533 - val_dense_3_accuracy: 0.9972 - val_dense_6_accuracy: 0.9606 - val_dense_9_accuracy: 0.9200\n",
            "Epoch 43/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0393 - dense_3_loss: 0.0087 - dense_6_loss: 0.0465 - dense_9_loss: 0.0393 - dense_3_accuracy: 0.9971 - dense_6_accuracy: 0.9838 - dense_9_accuracy: 0.9862 - val_loss: 0.3738 - val_dense_3_loss: 0.0080 - val_dense_6_loss: 0.1248 - val_dense_9_loss: 0.3724 - val_dense_3_accuracy: 0.9977 - val_dense_6_accuracy: 0.9598 - val_dense_9_accuracy: 0.9157\n",
            "Epoch 44/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0134 - dense_3_loss: 0.0091 - dense_6_loss: 0.0351 - dense_9_loss: 0.0134 - dense_3_accuracy: 0.9970 - dense_6_accuracy: 0.9882 - dense_9_accuracy: 0.9960 - val_loss: 0.3446 - val_dense_3_loss: 0.0083 - val_dense_6_loss: 0.1197 - val_dense_9_loss: 0.3438 - val_dense_3_accuracy: 0.9978 - val_dense_6_accuracy: 0.9633 - val_dense_9_accuracy: 0.9265\n",
            "Epoch 45/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0044 - dense_3_loss: 0.0084 - dense_6_loss: 0.0304 - dense_9_loss: 0.0044 - dense_3_accuracy: 0.9973 - dense_6_accuracy: 0.9904 - dense_9_accuracy: 0.9989 - val_loss: 0.3607 - val_dense_3_loss: 0.0081 - val_dense_6_loss: 0.1190 - val_dense_9_loss: 0.3596 - val_dense_3_accuracy: 0.9978 - val_dense_6_accuracy: 0.9630 - val_dense_9_accuracy: 0.9258\n",
            "Epoch 46/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0029 - dense_3_loss: 0.0080 - dense_6_loss: 0.0298 - dense_9_loss: 0.0029 - dense_3_accuracy: 0.9975 - dense_6_accuracy: 0.9903 - dense_9_accuracy: 0.9994 - val_loss: 0.3709 - val_dense_3_loss: 0.0082 - val_dense_6_loss: 0.1200 - val_dense_9_loss: 0.3699 - val_dense_3_accuracy: 0.9978 - val_dense_6_accuracy: 0.9630 - val_dense_9_accuracy: 0.9283\n",
            "Epoch 47/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0019 - dense_3_loss: 0.0087 - dense_6_loss: 0.0288 - dense_9_loss: 0.0019 - dense_3_accuracy: 0.9970 - dense_6_accuracy: 0.9905 - dense_9_accuracy: 0.9997 - val_loss: 0.3756 - val_dense_3_loss: 0.0082 - val_dense_6_loss: 0.1191 - val_dense_9_loss: 0.3750 - val_dense_3_accuracy: 0.9979 - val_dense_6_accuracy: 0.9636 - val_dense_9_accuracy: 0.9281\n",
            "Epoch 48/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0017 - dense_3_loss: 0.0089 - dense_6_loss: 0.0279 - dense_9_loss: 0.0017 - dense_3_accuracy: 0.9970 - dense_6_accuracy: 0.9910 - dense_9_accuracy: 0.9997 - val_loss: 0.3901 - val_dense_3_loss: 0.0082 - val_dense_6_loss: 0.1187 - val_dense_9_loss: 0.3887 - val_dense_3_accuracy: 0.9978 - val_dense_6_accuracy: 0.9623 - val_dense_9_accuracy: 0.9285\n",
            "Epoch 49/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0013 - dense_3_loss: 0.0088 - dense_6_loss: 0.0280 - dense_9_loss: 0.0013 - dense_3_accuracy: 0.9973 - dense_6_accuracy: 0.9911 - dense_9_accuracy: 0.9998 - val_loss: 0.3987 - val_dense_3_loss: 0.0082 - val_dense_6_loss: 0.1201 - val_dense_9_loss: 0.3985 - val_dense_3_accuracy: 0.9978 - val_dense_6_accuracy: 0.9630 - val_dense_9_accuracy: 0.9284\n",
            "Epoch 50/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 8.5197e-04 - dense_3_loss: 0.0089 - dense_6_loss: 0.0272 - dense_9_loss: 8.5364e-04 - dense_3_accuracy: 0.9971 - dense_6_accuracy: 0.9920 - dense_9_accuracy: 0.9999 - val_loss: 0.4067 - val_dense_3_loss: 0.0083 - val_dense_6_loss: 0.1200 - val_dense_9_loss: 0.4064 - val_dense_3_accuracy: 0.9978 - val_dense_6_accuracy: 0.9630 - val_dense_9_accuracy: 0.9284\n",
            "Epoch 51/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 9.5732e-04 - dense_3_loss: 0.0087 - dense_6_loss: 0.0271 - dense_9_loss: 9.5721e-04 - dense_3_accuracy: 0.9975 - dense_6_accuracy: 0.9918 - dense_9_accuracy: 0.9998 - val_loss: 0.4062 - val_dense_3_loss: 0.0082 - val_dense_6_loss: 0.1194 - val_dense_9_loss: 0.4067 - val_dense_3_accuracy: 0.9978 - val_dense_6_accuracy: 0.9625 - val_dense_9_accuracy: 0.9285\n",
            "Epoch 52/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 7.9118e-04 - dense_3_loss: 0.0082 - dense_6_loss: 0.0274 - dense_9_loss: 8.0764e-04 - dense_3_accuracy: 0.9975 - dense_6_accuracy: 0.9914 - dense_9_accuracy: 0.9998 - val_loss: 0.4122 - val_dense_3_loss: 0.0083 - val_dense_6_loss: 0.1192 - val_dense_9_loss: 0.4121 - val_dense_3_accuracy: 0.9979 - val_dense_6_accuracy: 0.9626 - val_dense_9_accuracy: 0.9285\n",
            "Epoch 53/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 8.1233e-04 - dense_3_loss: 0.0089 - dense_6_loss: 0.0282 - dense_9_loss: 8.2053e-04 - dense_3_accuracy: 0.9972 - dense_6_accuracy: 0.9909 - dense_9_accuracy: 0.9999 - val_loss: 0.4177 - val_dense_3_loss: 0.0083 - val_dense_6_loss: 0.1196 - val_dense_9_loss: 0.4174 - val_dense_3_accuracy: 0.9979 - val_dense_6_accuracy: 0.9627 - val_dense_9_accuracy: 0.9280\n",
            "Epoch 54/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 5.9857e-04 - dense_3_loss: 0.0088 - dense_6_loss: 0.0275 - dense_9_loss: 5.9831e-04 - dense_3_accuracy: 0.9973 - dense_6_accuracy: 0.9912 - dense_9_accuracy: 0.9999 - val_loss: 0.4166 - val_dense_3_loss: 0.0083 - val_dense_6_loss: 0.1187 - val_dense_9_loss: 0.4162 - val_dense_3_accuracy: 0.9979 - val_dense_6_accuracy: 0.9622 - val_dense_9_accuracy: 0.9289\n",
            "Epoch 55/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 6.6648e-04 - dense_3_loss: 0.0076 - dense_6_loss: 0.0271 - dense_9_loss: 6.6626e-04 - dense_3_accuracy: 0.9976 - dense_6_accuracy: 0.9912 - dense_9_accuracy: 0.9999 - val_loss: 0.4192 - val_dense_3_loss: 0.0083 - val_dense_6_loss: 0.1190 - val_dense_9_loss: 0.4189 - val_dense_3_accuracy: 0.9979 - val_dense_6_accuracy: 0.9630 - val_dense_9_accuracy: 0.9287\n",
            "Epoch 56/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 5.4031e-04 - dense_3_loss: 0.0086 - dense_6_loss: 0.0259 - dense_9_loss: 5.4066e-04 - dense_3_accuracy: 0.9975 - dense_6_accuracy: 0.9922 - dense_9_accuracy: 0.9999 - val_loss: 0.4201 - val_dense_3_loss: 0.0083 - val_dense_6_loss: 0.1187 - val_dense_9_loss: 0.4197 - val_dense_3_accuracy: 0.9979 - val_dense_6_accuracy: 0.9630 - val_dense_9_accuracy: 0.9296\n",
            "Epoch 57/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 4.7060e-04 - dense_3_loss: 0.0083 - dense_6_loss: 0.0261 - dense_9_loss: 4.7048e-04 - dense_3_accuracy: 0.9973 - dense_6_accuracy: 0.9919 - dense_9_accuracy: 0.9999 - val_loss: 0.4201 - val_dense_3_loss: 0.0083 - val_dense_6_loss: 0.1188 - val_dense_9_loss: 0.4197 - val_dense_3_accuracy: 0.9979 - val_dense_6_accuracy: 0.9629 - val_dense_9_accuracy: 0.9291\n",
            "Epoch 58/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 4.8975e-04 - dense_3_loss: 0.0087 - dense_6_loss: 0.0269 - dense_9_loss: 4.8971e-04 - dense_3_accuracy: 0.9973 - dense_6_accuracy: 0.9917 - dense_9_accuracy: 0.9999 - val_loss: 0.4209 - val_dense_3_loss: 0.0083 - val_dense_6_loss: 0.1188 - val_dense_9_loss: 0.4204 - val_dense_3_accuracy: 0.9979 - val_dense_6_accuracy: 0.9633 - val_dense_9_accuracy: 0.9294\n",
            "Epoch 59/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 4.9772e-04 - dense_3_loss: 0.0083 - dense_6_loss: 0.0272 - dense_9_loss: 4.9787e-04 - dense_3_accuracy: 0.9973 - dense_6_accuracy: 0.9918 - dense_9_accuracy: 0.9999 - val_loss: 0.4213 - val_dense_3_loss: 0.0082 - val_dense_6_loss: 0.1189 - val_dense_9_loss: 0.4208 - val_dense_3_accuracy: 0.9978 - val_dense_6_accuracy: 0.9633 - val_dense_9_accuracy: 0.9291\n",
            "Epoch 60/60\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 5.0586e-04 - dense_3_loss: 0.0082 - dense_6_loss: 0.0270 - dense_9_loss: 5.0564e-04 - dense_3_accuracy: 0.9973 - dense_6_accuracy: 0.9914 - dense_9_accuracy: 0.9999 - val_loss: 0.4208 - val_dense_3_loss: 0.0083 - val_dense_6_loss: 0.1185 - val_dense_9_loss: 0.4203 - val_dense_3_accuracy: 0.9978 - val_dense_6_accuracy: 0.9630 - val_dense_9_accuracy: 0.9296\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f7cfeb2ac18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR_3dA9VVEHa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "205df3cd-b68e-451b-c90c-78ba51de0d9a"
      },
      "source": [
        "\n",
        "'''model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              # optimizer=keras.optimizers.Adadelta(),\n",
        "              optimizer=sgd, \n",
        "              metrics=['accuracy'])'''\n",
        "\n",
        "#model.save(model_path)\n",
        "score = model.evaluate(x_test, [y_c1_test, y_c2_test, y_test], verbose=0)\n",
        "print('score is: ', score)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "score is:  [0.42076459857193405, 0.008339118212461472, 0.11878246814012527, 0.42069384455680847, 0.9977999925613403, 0.9629999995231628, 0.9296000003814697]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oirxr40ftyo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot the loss and accuracy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "loss = history.history['loss']\n",
        "dense_3_loss = history.history['dense_3_loss']\n",
        "dense_6_loss = history.history['dense_6_loss']\n",
        "dense_9_loss = history.history['dense_9_loss']\n",
        "dense_3_accuracy = history.history['dense_3_accuracy']\n",
        "dense_6_accuracy = history.history['dense_6_accuracy']\n",
        "dense_9_accuracy = history.history['dense_9_accuracy']\n",
        "val_loss = history.history['val_loss']\n",
        "val_dense_3_loss = history.history['val_dense_3_loss']\n",
        "val_dense_6_loss = history.history['val_dense_6_loss']\n",
        "val_dense_9_loss = history.history['val_dense_9_loss']\n",
        "val_dense_3_accuracy = history.history['val_dense_3_accuracy']\n",
        "val_dense_6_accuracy = history.history['val_dense_6_accuracy']\n",
        "val_dense_9_accuracy = history.history['val_dense_9_accuracy']\n",
        "\n",
        "epochs = range(1, 60)\n",
        "\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.plot(epochs, dense_3_accuracy, 'red', label='Training C1 accuracy')\n",
        "plt.plot(epochs, dense_6_accuracy, 'blue', label='Training C2 accuracy')\n",
        "plt.plot(epochs, dense_9_accuracy, 'green', label='Training F accuracy')\n",
        "plt.plot(epochs, val_dense_3_accuracy, 'yellow', label='Validation C1 accuracy')\n",
        "plt.plot(epochs, val_dense_6_accuracy, 'violet', label='Validation C2 accuracy')\n",
        "plt.plot(epochs, val_dense_9_accuracy, 'gray', label='Validation F accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "plt.title('Training and validation loss')\n",
        "plt.plot(epochs, dense_3_loss, 'red', label='Training C1 loss')\n",
        "plt.plot(epochs, dense_6_loss, 'blue', label='Training C2 loss')\n",
        "plt.plot(epochs, dense_9_loss, 'green', label='Training F loss')\n",
        "plt.plot(epochs, val_dense_3_loss, 'yellow', label='Validation C1 loss')\n",
        "plt.plot(epochs, val_dense_6_loss, 'violet', label='Validation C2 loss')\n",
        "plt.plot(epochs, val_dense_9_loss, 'gray', label='Validation F loss')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}